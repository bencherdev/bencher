---
title: "SQLite Performance Tuning"
description: "Learn why Bencher benchmarked, profiled, and tuned its SQLite database to enable better continuous benchmarking."
heading: "Why SQLite Performance Tuning made Bencher 30x Faster"
published: "2024-03-19T07:39:00Z"
modified: "2024-03-20T07:36:00Z"
sortOrder: -2024.0411
---

import BencherFooter from "../../../chunks/learn/en/bencher-footer.mdx";

A couple of days ago, I got [feedback from a user][github bitcoin 27284]
that [their Bencher Perf Page][0xb10c perf page] was taking a while to load.
So I decided to check it out, and oh, man were they being nice.
It took sooo long to load! Embarrassingly long.
Especially for the leading [Continuous Benchmarking][continuous benchmarking] tool.

In the past, I've used the [Rustls Perf Page] as my litmus test.
They have 112 benchmarks and [one of the most impressive Continuous Benchmarking setups out there][rustls case study].
It used to take about 5 seconds load. This time around it took... ‚è≥üëÄ ... 38.8 seconds!
With that sort of latency, I had to dig in. Performance bugs are bugs, after all!

[github bitcoin 27284]: https://github.com/bitcoin/bitcoin/issues/27284#issuecomment-2046870296

[0xb10c perf page]: /perf/0xb10c-s-bitcoin-core
[continuous benchmarking]: /docs/explanation/continuous-benchmarking/
[rustls perf page]: /perf/rustls-821705769?notify_kind=alert&notify_text=Learn+more+about+continuous+benchmarking+for+the+Rustls+project.&notify_timeout=2147483647&notify_link_url=https%3A%2F%2Fbencher.dev%2Flearn%2Fcase-study%2Frustls%2F&notify_link_text=Read+the+case+study
[rustls case study]: /learn/case-study/rustls/

## Background

From the very start, I knew that the [Bencher Perf API][perf query]
was going to be one of the most demanding endpoints performance wise.
I believe the main reason that so many folks have had to [reinvent the benchmark tracking wheel][prior art]
is that the existing off-the-shelf tools don't handle the high dimensionality required.
By "high dimensionality", I mean being able to track performance over time and across multiple dimensions:
[Branches][branch], [Testbeds][testbed], [Benchmarks][benchmarks], and [Measures][measures].
This ability to slice and dice across five different dimensions leads to a very complex model.

Because of this inherent complexity and the nature of the data,
I considered using a time series database for Bencher.
In the end though, I settled on using SQLite instead.
I figured it was better to [do things that don't scale][do things that dont scale]
than to spend the extra time learning an entirely new database architecture that may or may not actually help.

Over time, the demands on the Bencher Perf API have also increased.
Originally, you had to select all of the dimensions that you wanted to plot manually.
This created a lot of friction for users to get to a useful plot.
To solve this, I [added a list of the most recent Reports][github issue 133] to the Perf Pages,
and by default, the most recent Report was selected and plotted.
This means that if there were 112 benchmarks in the most recent Report, then all 112 would be plotted.
The model also got even more complicated with the ability to track and visualize [Threshold Boundaries][thresholds].

With this in mind, I made a few performance related improvements.
Since the Perf Plot needs the most recent Report to start plotting,
I refactored the [Reports API][reports api] to get a Report's result data in a single call to the database instead of iterating.
The time window for the default Report query was set to four weeks, instead of being unbounded.
I also drastically limited the scope of all database handles, reducing lock contention.
To help communicate to users, I added a status bar spinner for both [the Perf Plot][bencher v0317] and [the dimension tabs][bencher v045].

I also had a failed attempt last fall at using a composite query to get all Perf results into a single query.
This lead to me hitting the [Rust type system recursion limit][recusion limit],
overflowing the stack on my M1 MacBook Pro,
suffering through insane (much longer than 38 seconds) compile times,
and finally dead ending at [SQLite's max number of terms in a compound select statement][sqlite limits].

With all of that under my belt, I knew that I really needed to dig in here
and put my performance engineer pants on.
I had never profiled a SQLite database before,
and honestly, I had never really profiled _any_ database before.
Now wait a minute you might might be thinking.
[My LinkedIn profile][linkedin epompeii] says I was a "Database Administrator" for almost two years.
And I _never_ profiled a database‚ÄΩ
Yep. That's a story for another time I suppose.

[do things that dont scale]: https://paulgraham.com/ds.html
[github issue 133]: https://github.com/bencherdev/bencher/issues/133
[recusion limit]: https://doc.rust-lang.org/reference/attributes/limits.html#the-recursion_limit-attribute
[sqlite limits]: https://www.sqlite.org/limits.html
[linkedin epompeii]: https://www.linkedin.com/in/epompeii/

[perf query]: /docs/api/projects/perf/#get-v0projectsprojectperf
[prior art]: /docs/reference/prior-art/#benchmark-tracking-tools
[branch]: /docs/explanation/benchmarking/#branch
[testbed]: /docs/explanation/benchmarking/#testbed
[benchmarks]: /docs/explanation/benchmarking/#benchmarks
[measures]: /docs/explanation/benchmarking/#measures
[thresholds]: /docs/explanation/thresholds/
[reports api]: /docs/api/projects/reports/#get-v0projectsprojectreports
[bencher v0317]: /docs/reference/changelog/#v0317
[bencher v045]: /docs/reference/changelog/#v045

## From ORM to SQL Query

The first hurdle I ran into was getting the SQL query out of my Rust code.
I use [Diesel][github diesel] as the object‚Äìrelational mapper (ORM) for Bencher.

> üê∞ Fun Fact: Diesel uses Bencher for their [Relative Continuous Benchmarking][relative continuous benchmarking].
> Check out [the Diesel Perf Page][diesel perf page]!

Diesel creates parameterized queries.
It sends the SQL query and its bind parameters separately to the database.
That is, the substitution is done by the database.
Therefore, Diesel cannot provide a complete query to the user.
The best method that I found was using [the `diesel::debug_query` function][diesel debug query] to output the parameterized query:

```rust
Query { sql: "SELECT `branch`.`id`, `branch`.`uuid`, `branch`.`project_id`, `branch`.`name`, `branch`.`slug`, `branch`.`start_point_id`, `branch`.`created`, `branch`.`modified`, `testbed`.`id`, `testbed`.`uuid`, `testbed`.`project_id`, `testbed`.`name`, `testbed`.`slug`, `testbed`.`created`, `testbed`.`modified`, `benchmark`.`id`, `benchmark`.`uuid`, `benchmark`.`project_id`, `benchmark`.`name`, `benchmark`.`slug`, `benchmark`.`created`, `benchmark`.`modified`, `measure`.`id`, `measure`.`uuid`, `measure`.`project_id`, `measure`.`name`, `measure`.`slug`, `measure`.`units`, `measure`.`created`, `measure`.`modified`, `report`.`uuid`, `report_benchmark`.`iteration`, `report`.`start_time`, `report`.`end_time`, `version`.`number`, `version`.`hash`, `threshold`.`id`, `threshold`.`uuid`, `threshold`.`project_id`, `threshold`.`measure_id`, `threshold`.`branch_id`, `threshold`.`testbed_id`, `threshold`.`model_id`, `threshold`.`created`, `threshold`.`modified`, `model`.`id`, `model`.`uuid`, `model`.`threshold_id`, `model`.`test`, `model`.`min_sample_size`, `model`.`max_sample_size`, `model`.`window`, `model`.`lower_boundary`, `model`.`upper_boundary`, `model`.`created`, `model`.`replaced`, `boundary`.`id`, `boundary`.`uuid`, `boundary`.`threshold_id`, `boundary`.`model_id`, `boundary`.`metric_id`, `boundary`.`baseline`, `boundary`.`lower_limit`, `boundary`.`upper_limit`, `alert`.`id`, `alert`.`uuid`, `alert`.`boundary_id`, `alert`.`boundary_limit`, `alert`.`status`, `alert`.`modified`, `metric`.`id`, `metric`.`uuid`, `metric`.`report_benchmark_id`, `metric`.`measure_id`, `metric`.`value`, `metric`.`lower_value`, `metric`.`upper_value` FROM (((`metric` INNER JOIN ((`report_benchmark` INNER JOIN ((`report` INNER JOIN (`version` INNER JOIN (`branch_version` INNER JOIN `branch` ON (`branch_version`.`branch_id` = `branch`.`id`)) ON (`branch_version`.`version_id` = `version`.`id`)) ON (`report`.`version_id` = `version`.`id`)) INNER JOIN `testbed` ON (`report`.`testbed_id` = `testbed`.`id`)) ON (`report_benchmark`.`report_id` = `report`.`id`)) INNER JOIN `benchmark` ON (`report_benchmark`.`benchmark_id` = `benchmark`.`id`)) ON (`metric`.`report_benchmark_id` = `report_benchmark`.`id`)) INNER JOIN `measure` ON (`metric`.`measure_id` = `measure`.`id`)) LEFT OUTER JOIN (((`boundary` INNER JOIN `threshold` ON (`boundary`.`threshold_id` = `threshold`.`id`)) INNER JOIN `model` ON (`boundary`.`model_id` = `model`.`id`)) LEFT OUTER JOIN `alert` ON (`alert`.`boundary_id` = `boundary`.`id`)) ON (`boundary`.`metric_id` = `metric`.`id`)) WHERE ((((((`branch`.`uuid` = ?) AND (`testbed`.`uuid` = ?)) AND (`benchmark`.`uuid` = ?)) AND (`measure`.`uuid` = ?)) AND (`report`.`start_time` >= ?)) AND (`report`.`end_time` <= ?)) ORDER BY `version`.`number`, `report`.`start_time`, `report_benchmark`.`iteration`", binds: [BranchUuid(a7d8366a-4f9b-452e-987e-2ae56e4bf4a3), TestbedUuid(5b4a6f3e-a27d-4cc3-a2ce-851dc6421e6e), BenchmarkUuid(88375e7c-f1e0-4cbb-bde1-bdb7773022ae), MeasureUuid(b2275bbc-2044-4f8e-aecd-3c739bd861b9), DateTime(2024-03-12T12:23:38Z), DateTime(2024-04-11T12:23:38Z)] }
```

And then hand cleaning and parameterizing the query into valid SQL:

```sql
SELECT branch.id, branch.uuid, branch.project_id, branch.name, branch.slug, branch.start_point_id, branch.created, branch.modified, testbed.id, testbed.uuid, testbed.project_id, testbed.name, testbed.slug, testbed.created, testbed.modified, benchmark.id, benchmark.uuid, benchmark.project_id, benchmark.name, benchmark.slug, benchmark.created, benchmark.modified, measure.id, measure.uuid, measure.project_id, measure.name, measure.slug, measure.units, measure.created, measure.modified, report.uuid, report_benchmark.iteration, report.start_time, report.end_time, version.number, version.hash, threshold.id, threshold.uuid, threshold.project_id, threshold.measure_id, threshold.branch_id, threshold.testbed_id, threshold.model_id, threshold.created, threshold.modified, model.id, model.uuid, model.threshold_id, model.test, model.min_sample_size, model.max_sample_size, model.window, model.lower_boundary, model.upper_boundary, model.created, model.replaced, boundary.id, boundary.uuid, boundary.threshold_id, boundary.model_id, boundary.metric_id, boundary.baseline, boundary.lower_limit, boundary.upper_limit, alert.id, alert.uuid, alert.boundary_id, alert.boundary_limit, alert.status, alert.modified, metric.id, metric.uuid, metric.report_benchmark_id, metric.measure_id, metric.value, metric.lower_value, metric.upper_value FROM (((metric INNER JOIN ((report_benchmark INNER JOIN ((report INNER JOIN (version INNER JOIN (branch_version INNER JOIN branch ON (branch_version.branch_id = branch.id)) ON (branch_version.version_id = version.id)) ON (report.version_id = version.id)) INNER JOIN testbed ON (report.testbed_id = testbed.id)) ON (report_benchmark.report_id = report.id)) INNER JOIN benchmark ON (report_benchmark.benchmark_id = benchmark.id)) ON (metric.report_benchmark_id = report_benchmark.id)) INNER JOIN measure ON (metric.measure_id = measure.id)) LEFT OUTER JOIN (((boundary INNER JOIN threshold ON (boundary.threshold_id = threshold.id)) INNER JOIN model ON (boundary.model_id = model.id)) LEFT OUTER JOIN alert ON (alert.boundary_id = boundary.id)) ON (boundary.metric_id = metric.id)) WHERE ((((((branch.uuid = 'a7d8366a-4f9b-452e-987e-2ae56e4bf4a3') AND (testbed.uuid = '5b4a6f3e-a27d-4cc3-a2ce-851dc6421e6e')) AND (benchmark.uuid = '88375e7c-f1e0-4cbb-bde1-bdb7773022ae')) AND (measure.uuid = 'b2275bbc-2044-4f8e-aecd-3c739bd861b9')) AND (report.start_time >= 0)) AND (report.end_time <= 1712838648197)) ORDER BY version.number, report.start_time, report_benchmark.iteration;
```

If you know of a better way, please let me know!
This is the way that [the maintainer of the project suggested][stackoverflow diesel] though,
so I just went with it.
Now that I had a SQL query, I was finally ready to... read a whole lot of documentation.

[github diesel]: https://github.com/diesel-rs/diesel
[diesel debug query]: https://docs.rs/diesel/2.1.5/diesel/fn.debug_query.html
[stackoverflow diesel]: https://stackoverflow.com/questions/76467831/ho-to-get-final-sql-query-from-diesel

[relative continuous benchmarking]: /docs/how-to/track-benchmarks/#relative-continuous-benchmarking
[diesel perf page]: /perf/diesel

## SQLite Query Planner

The SQLite website has [great documentation for its Query Planner][sqlite query planner].
It explains exactly how SQLite goes about executing your SQL query,
and it teaches you which indexes are useful and what operations to look out for, like full table scans.

In order to see how the Query Planner would execute my Perf query,
I needed to add a new tool to my tool belt: [`EXPLAIN QUERY PLAN`][eqp]
You can either prefix your SQL query with `EXPLAIN QUERY PLAN`
or run the `.eqp on` dot command before your query.
Either way, I got a result that looks like this:

```
QUERY PLAN
|--MATERIALIZE (join-5)
|  |--SCAN boundary
|  |--SEARCH threshold USING INTEGER PRIMARY KEY (rowid=?)
|  |--SEARCH model USING INTEGER PRIMARY KEY (rowid=?)
|  |--BLOOM FILTER ON alert (boundary_id=?)
|  `--SEARCH alert USING AUTOMATIC COVERING INDEX (boundary_id=?) LEFT-JOIN
|--SEARCH branch USING INDEX sqlite_autoindex_branch_1 (uuid=?)
|--SEARCH measure USING INDEX sqlite_autoindex_measure_1 (uuid=?)
|--SEARCH benchmark USING INDEX sqlite_autoindex_benchmark_1 (uuid=?)
|--SEARCH testbed USING INDEX sqlite_autoindex_testbed_1 (uuid=?)
|--SCAN metric
|--SEARCH report_benchmark USING INTEGER PRIMARY KEY (rowid=?)
|--SEARCH report USING INTEGER PRIMARY KEY (rowid=?)
|--SEARCH version USING INTEGER PRIMARY KEY (rowid=?)
|--SEARCH branch_version USING COVERING INDEX sqlite_autoindex_branch_version_1 (branch_id=? AND version_id=?)
|--BLOOM FILTER ON (join-5) (metric_id=?)
|--SEARCH (join-5) USING AUTOMATIC COVERING INDEX (metric_id=?) LEFT-JOIN
`--USE TEMP B-TREE FOR ORDER BY
```

Oh, boy!
There is a lot here.
But the three big things that jumped out to me where:

1. SQLite is creating a materialized view on-the-fly that scans the _entire_ `boundary` table
2. SQLite is then scanning the _entire_ `metric` table
3. SQLite is creating two on the fly indexes

And just how big are the `metric` and `boundary` tables?
Well they just so happen to be the two largest tables,
as they are where all the [Metrics][metrics] and [Boundaries][thresholds] are stored.

Since this was my first SQLite performance tuning rodeo,
I wanted to consult an expert before making any changes.

[sqlite query planner]: https://www.sqlite.org/queryplanner.html
[eqp]: https://www.sqlite.org/eqp.html

[thresholds]: /docs/explanation/thresholds/
[metrics]: /docs/explanation/benchmarking/#metrics

## SQLite Expert

SQLite has an experimental "expert" mode that can be enabled with [the `.expert on` command][expert on].
It suggests indexes for queries, so I decided to give it a try.
This is what it suggested:

```
CREATE INDEX report_benchmark_idx_fc6f3e5b ON report_benchmark(report_id, benchmark_id);
CREATE INDEX report_idx_55aae6d8 ON report(testbed_id, end_time);
CREATE INDEX alert_idx_e1882f70 ON alert(boundary_id);

MATERIALIZE (join-5)
SCAN boundary
SEARCH threshold USING INTEGER PRIMARY KEY (rowid=?)
SEARCH model USING INTEGER PRIMARY KEY (rowid=?)
SEARCH alert USING INDEX alert_idx_e1882f70 (boundary_id=?) LEFT-JOIN
SEARCH branch USING INDEX sqlite_autoindex_branch_1 (uuid=?)
SEARCH benchmark USING INDEX sqlite_autoindex_benchmark_1 (uuid=?)
SEARCH testbed USING INDEX sqlite_autoindex_testbed_1 (uuid=?)
SEARCH measure USING INDEX sqlite_autoindex_measure_1 (uuid=?)
SEARCH report USING INDEX report_idx_55aae6d8 (testbed_id=? AND end_time<?)
SEARCH version USING INTEGER PRIMARY KEY (rowid=?)
SEARCH branch_version USING COVERING INDEX sqlite_autoindex_branch_version_1 (branch_id=? AND version_id=?)
SEARCH report_benchmark USING INDEX report_benchmark_idx_fc6f3e5b (report_id=? AND benchmark_id=?)
SEARCH metric USING INDEX sqlite_autoindex_metric_2 (report_benchmark_id=? AND measure_id=?)
BLOOM FILTER ON (join-5) (metric_id=?)
SEARCH (join-5) USING AUTOMATIC COVERING INDEX (metric_id=?) LEFT-JOIN
USE TEMP B-TREE FOR ORDER BY
```

This is definitely an improvement!
It got rid of the scan on the `metric` table and both of the on-the-fly indexes.
Honestly, I wouldn't have gotten the first two indexes on my own.
Thank you, SQLite Expert!

```sql
CREATE INDEX index_report_testbed_end_time ON report(testbed_id, end_time);
CREATE INDEX index_report_benchmark ON report_benchmark(report_id, benchmark_id);
CREATE INDEX index_alert_boundary ON alert(boundary_id);
```

Now the only thing left to get rid of is that darn on-the-fly materialized view.

[expert on]: https://sqlite.org/cli.html#special_commands_to_sqlite3_dot_commands_

## Materialized View

When I added the ability to track and visualize [Threshold Boundaries][thresholds] last year,
I had a decision to make in the database model.
There is a 1-to-0/1 relationship between a Metric and its corresponding Boundary.
That is a Metric can relate to zero or one Boundary, and a Boundary can only ever relate to one Metric.
So I could have just expanded the `metric` table to include all of the `boundary` data with every `boundary` related field being nullable.
Or I could create a separate `boundary` table with a `UNIQUE` foreign key to `metric` table.
To me the latter option felt a lot cleaner, and I figured I could always deal with any performance implications later.

These were the queries used to create the `metric` and `boundary` tables:

```sql
CREATE TABLE metric (
    id INTEGER PRIMARY KEY NOT NULL,
    uuid TEXT NOT NULL UNIQUE,
    report_benchmark_id INTEGER NOT NULL,
    measure_id INTEGER NOT NULL,
    value DOUBLE NOT NULL,
    lower_value DOUBLE,
    upper_value DOUBLE,
    FOREIGN KEY (report_benchmark_id) REFERENCES report_benchmark (id) ON DELETE CASCADE,
    FOREIGN KEY (measure_id) REFERENCES measure (id),
    UNIQUE(report_benchmark_id, measure_id)
);
```

```sql
CREATE TABLE boundary (
    id INTEGER PRIMARY KEY NOT NULL,
    uuid TEXT NOT NULL UNIQUE,
    threshold_id INTEGER NOT NULL,
    statistic_id INTEGER NOT NULL,
    metric_id INTEGER NOT NULL UNIQUE,
    baseline DOUBLE NOT NULL,
    lower_limit DOUBLE,
    upper_limit DOUBLE,
    FOREIGN KEY (threshold_id) REFERENCES threshold (id),
    FOREIGN KEY (statistic_id) REFERENCES statistic (id),
    FOREIGN KEY (metric_id) REFERENCES metric (id) ON DELETE CASCADE
);
```

And it turns out "later" had arrived.
I tried to simply add an index for `boundary(metric_id)` but that did not help.
I believe the reason has to do with the fact that the Perf query is originating from the `metric` table
and because that relationship is 0/1 or put another way, nullable it has to be scanned (O(n))
and cannot be searched (O(log(n))).

This left me with one clear option.
I needed to create a materialized view that flattened the `metric` and `boundary` relationship
to keep SQLite from having to create an on-the-fly materialized view.

This is the query I used to create the new `metric_boundary` materialized view:

```sql
CREATE VIEW metric_boundary AS
SELECT metric.id AS metric_id,
    metric.uuid AS metric_uuid,
    metric.report_benchmark_id,
    metric.measure_id,
    metric.value,
    metric.lower_value,
    metric.upper_value,
    boundary.id,
    boundary.uuid AS boundary_uuid,
    boundary.threshold_id AS threshold_id,
    boundary.model_id,
    boundary.baseline,
    boundary.lower_limit,
    boundary.upper_limit
FROM metric
    LEFT OUTER JOIN boundary ON (boundary.metric_id = metric.id);
```

With this solution, I'm trading off space for runtime performance.
How much space?
Surprisingly only about a 4% increase, even though this view is for the two largest tables in the database.
Best of all, it lets me have my cake and eat it too in my source code.

[Creating a materialized view with Diesel][diesel view] was surprisingly easy.
I just had to use the exact same macros that Diesel uses when generating my normal schema.
With that said, I learned to appreciate Diesel a lot more throughout this experience.
See [Bonus Bug][bonus bug] for all the juicy details.

[diesel view]: https://deterministic.space/diesel-view-table-trick.html

[thresholds]: /docs/explanation/thresholds/

[bonus bug]: #bonus-bug

## Wrap Up

With the three new indexes and a materialized view added, with is what the Query Planner showed me:

```
QUERY PLAN
|--SEARCH branch USING INDEX sqlite_autoindex_branch_1 (uuid=?)
|--SEARCH testbed USING INDEX sqlite_autoindex_testbed_1 (uuid=?)
|--SEARCH benchmark USING INDEX sqlite_autoindex_benchmark_1 (uuid=?)
|--SEARCH measure USING INDEX sqlite_autoindex_measure_1 (uuid=?)
|--SEARCH report USING INDEX index_report_testbed_end_time (testbed_id=? AND end_time<?)
|--SEARCH version USING INTEGER PRIMARY KEY (rowid=?)
|--SEARCH branch_version USING COVERING INDEX sqlite_autoindex_branch_version_1 (branch_id=? AND version_id=?)
|--SEARCH report_benchmark USING INDEX index_report_benchmark (report_id=? AND benchmark_id=?)
|--SEARCH metric USING INDEX sqlite_autoindex_metric_2 (report_benchmark_id=? AND measure_id=?)
|--SEARCH boundary USING INDEX sqlite_autoindex_boundary_2 (metric_id=?) LEFT-JOIN
|--SEARCH threshold USING INTEGER PRIMARY KEY (rowid=?) LEFT-JOIN
|--SEARCH model USING INTEGER PRIMARY KEY (rowid=?) LEFT-JOIN
|--SEARCH alert USING INDEX index_alert_boundary (boundary_id=?) LEFT-JOIN
`--USE TEMP B-TREE FOR ORDER BY
```

Look at all of those beautify `SEARCH`es all with existing indexes! ü•≤

Now it was time for the final test.
How fast does that Rustls Perf page load?

Here I'll even give you anchor tag. Click it and then refresh the page.

### Performance Matters

<iframe src="https://bencher.dev/perf/rustls-821705769/embed?key=false&reports_per_page=8&branches_per_page=8&testbeds_per_page=8&benchmarks_per_page=8&reports_page=1&branches_page=1&testbeds_page=1&benchmarks_page=1&clear=true&tab=reports&measures=cc24a100-055a-4da8-b5d1-206553ee5cab&branches=28fae530-2b53-4482-acd4-47e16030d54f&testbeds=62ed31c3-8a58-479c-b828-52521ed67bee&benchmarks=984a5667-5118-4f2c-9366-7435d2795721%2Ce7c72328-3f07-4745-b72b-76336368dfe9%2C2ff2c16d-f5f4-42df-92ca-684b8de71d82%2C976fcf6f-335b-47ba-930c-6d343c5ccc70%2C6965ab70-41d5-447e-8e0f-d54b5a8ae6c1%2Cc43c8a82-043d-42f6-ab99-b2c75aba66aa%2C765d4159-3244-4077-9381-930ac13161b7%2Cbd1e6550-4f50-439b-a5ac-cf543a69f160%2Ccbf8ea66-ac2a-43b7-9a20-cfe88399f6d0%2C2c64ddd4-83d4-4b80-b8e8-c9582235c62d%2C2d9bc1d7-e061-4c95-ace0-8a05d3b1fde2%2C56e6380f-063a-4ad1-83df-ebf61c260c08%2Ca2b88fbb-7d87-40aa-af02-888b98e343c3%2C7509f224-4252-44ae-8515-d26c81b78d6b%2C7d0498fe-eca0-4e21-973d-bbb6a526d472%2Cb9da6896-ff02-415b-ab0f-bcb6ecb0fb64%2C322c7016-425e-4d82-afd1-01e24cb179bd%2Cccefd2ff-41c6-4de3-948d-e136b0b11688%2Cf9897560-81f6-4577-bb90-3ebb5d7cff7d%2C64a4d1b0-638a-40dc-95de-a76fff6b2e90%2C32b87347-46f4-4ff0-b9eb-3963ad67e0b3%2C4b808a30-831a-482e-8bd1-9cfff915604e%2C6d132a96-56ae-45b9-a08a-aceff1d0b82d%2Cfb38a789-b06b-4647-b09f-1283dcba177d%2C45bf02da-3519-49f1-aaac-54f9e9cdf62a%2Cae33d1c5-4a3f-4478-b16c-de93c426e184%2C2fcb9b93-6c2a-4e7d-8a9f-6f5aa3311dd1%2C14f5f2a5-7390-4681-bc48-8ea78e69f3e2%2C66b52860-1cc3-46ad-970c-0bea62ee3d41%2C7793437c-ded4-45c9-ac78-cdc7bb3be9b7%2Cba214405-0b4d-4260-9bd2-9dc82c5e0030%2Cc0c1ab86-8306-4ce4-b120-ec49b5d7f589%2Ccc637e9f-cb92-4ce7-a6c1-2ac20f36464a%2C48df02b2-7459-4176-9d39-561e2068b6d2%2Cbefc3335-fdc0-4944-bb66-631dc6246d28%2Cdc910511-44a3-42e3-99c9-aa84594c8efb%2Ce87092af-7dd7-4a18-918b-9e27e5d64f0f%2Cc5bc4ea9-692c-499b-b7b9-f731d166b3b5%2C3e32a13e-2ae8-4994-a8e1-190a2b6d6538%2C65ff492a-0783-40a0-85ba-23b34991b6f6%2C8b83ef1b-7981-49e8-abe0-be5448ca4bf1%2Ccab2f4b6-2dbf-4e3b-ad91-bf31c14891e6%2Ceb562905-b2a5-4565-892e-988e715606d2%2C5d88ef14-739e-4bdc-9c9e-53eb01a33590%2C7aa2abd5-1433-48e3-ad91-7cd750e66535%2Cf2cc9ac0-2b61-439d-a931-f5431cacd0e5%2C4e0456b5-0e19-4cac-984f-fa2ea35e216d%2C3f51aabc-6baa-453e-addc-e74ecb87685f%2C2cc31ac4-268d-48eb-9d25-e76e0df005ee%2C76bf7f55-5399-448b-a5e5-d5d45f7767cd%2C9c72b6eb-0027-4979-8ce9-ea34056f749d%2C35869fe6-94d1-423a-8973-1057cb5f13aa%2Cdfdbfbb7-8bec-4b59-9350-1edc5e1a6e41%2Cfe947530-66d5-419a-9e74-54aae7d4eab1%2C8076d008-8356-4de7-93b5-a5b893dacfd0%2C94f6a932-12ee-40b3-addb-71891a649aa7%2Cfb16bfe8-df31-4dad-81da-74d8832e5ec4%2C12dcbfee-49cf-43fc-a938-4e88cbf35d3b%2C0a38b340-537a-47a4-b19c-84c91ab79b6f%2C492a79c9-076a-4e1f-8ed0-170e92357286%2C9df0c067-3771-4b97-8a37-da73b633c317%2C03ee13ec-bfd0-4916-91ea-d0b1ea8c0f66%2C29790ac8-1c2f-407a-8c29-d4a32ca635db%2C4c215b08-cec8-47b0-83a7-1c3cbb81a773%2C1efabfae-b2cb-4ef0-b023-42a6144a0e24%2Ccbaf202f-9306-4a32-a8bc-e3c2619c2d7b%2C917eec86-1d6e-4539-9dea-b88cb2842797%2Cb7f1f8ff-ffa8-418b-9179-f72a91092355%2Ce5788d0e-3d66-4e56-9833-9349344a6f31%2C8333647a-447d-42d9-947a-bdea787331a3%2C2aa52662-3378-4390-88f9-02b30ac729ea%2C7defce9c-33c2-4d71-a844-9bbbc351b57c%2C329724c4-5424-4a16-bdf1-b33802189548%2Cad783c5a-7e0b-4ab0-a03c-745c6b28de06%2Ce370f05e-a833-449e-85d7-ea71378afa19%2Cf7e511a8-7f64-4a2b-9a53-284aeeee97a0%2C79f3050c-1063-4473-9c74-7fa0cbf21288%2Cd877a3f4-9032-4372-a810-5d9a35098da5%2C362a75b3-686b-4383-8645-ddae2c7778be%2C4a0a6c5b-7f7d-4fba-8432-03bf8002262e%2Ca2561e3f-dba4-4f99-859f-2aab13809955%2C48aefc3f-238a-42d7-b9cc-7f9f701ad557%2C3c465073-61be-4770-a3fd-0b16f2569925%2Ccb364188-0951-4fe6-b434-a2016b69add4%2C01c64876-e7c7-4064-a1e5-56359f9f37a0%2Cd9f9983f-19bf-4b23-88b4-6ff4aa9e06ec%2C76373b00-fffe-4f13-b2b6-49db6387cb09%2Ca6ed61ba-636b-4293-b1cc-73c96e7085e8%2C1dce272e-10c5-46cd-ae61-2e79ecb5798b%2C56d39e20-9049-4b64-861e-5c0e1c410b91%2C4eda85e3-97e8-43c2-ac5a-690d54a9ffdb%2C30f6c914-044a-4116-87a0-090b5f6c997a%2C6606cbcc-44ee-4fed-9dfe-d3e26cdcc601%2C429ef111-2900-4688-92f3-babe058d1b71%2C4362d86c-f5da-48d1-b285-ab60d3b4a798%2Caeaccabc-7100-495f-bcb0-56492c1ca898%2Ccf5cf2b2-0139-4e40-ad62-e21797c0ed93%2Ca9e84b4e-9987-4157-8acc-3fa002eafd5d%2Cc11e6edd-6050-40c9-ad29-7199e2c8a184%2C8c46baed-03fc-4f1b-a0b8-6cba48c5f8c4%2C55db0396-352c-47cc-a361-6584a46fec31%2Ceee69ef8-df02-4f40-910e-16b2def8e584%2C35f76d63-63e7-433e-ad21-7d6f2481d57a%2Cbfd510c0-ce81-4b88-93c5-e3c513869e24%2C66cb4d61-4617-47e2-84ce-27cf2d265638%2C199494dc-f99f-4511-a37a-50f8024f460a%2C11cdc840-8125-4270-ab39-3174e3ef2ba8%2Ccad39509-6cb6-4282-88d8-84dab98f3a01%2Ccf65fe46-3c8e-40a4-85dc-22dbb9505f23%2C6e6fd6dd-7bf7-4ae7-a5de-8218cd96b0ec%2Cebed27c4-fa21-49d0-8231-f46a1ccba456%2C71638ebc-172f-4fad-a410-ac60c69dc1db&start_time=1709795759000&notify_kind=alert&notify_text=Learn+more+about+continuous+benchmarking+for+the+Rustls+project.&notify_timeout=2147483647&notify_link_url=https%3A%2F%2Fbencher.dev%2Flearn%2Fcase-study%2Frustls%2F&notify_link_text=Read+the+case+study&report=bfc9f49e-25e2-4111-8384-91619ffb9d48&end_time=1712387853000" title="rustls" width="100%" height="820px" allow="fullscreen" style="border: 1rem solid #ed6704;"></iframe>

<br />
<br />

<BencherFooter />

<br />
<hr />
<br />

## Addendum on Dogfooding

I'm already [dogfooding Bencher with Bencher][bencher perf],
but all of the existing [benchmark harness adapters][adapters] are for micro-benchmarking harnesses.
Most HTTP harnesses are really load testing harnesses,
and [load testing is different than benchmarking][continuous benchmarking load testing].
Further, I'm not looking to expand Bencher into load testing anytime soon.
That is a very different use case that would require very different design considerations,
like that time series database for instance.
Even if I did have load testing in place,
I would really need to be running against a fresh pull of production data for this to have been caught.
The performance differences of this change were negligible on my test database
due to the size of the tables at play.

<details>
    <summary>Click to view test database benchmark results</summary>
    <br />

    Before:

    ```
    Run Time: real 0.081 user 0.019532 sys 0.005618
    Run Time: real 0.193 user 0.022192 sys 0.003368
    Run Time: real 0.070 user 0.021390 sys 0.003369
    Run Time: real 0.062 user 0.022676 sys 0.002290
    Run Time: real 0.057 user 0.012053 sys 0.006638
    Run Time: real 0.052 user 0.018797 sys 0.002016
    Run Time: real 0.059 user 0.022806 sys 0.002437
    Run Time: real 0.066 user 0.021869 sys 0.004525
    Run Time: real 0.060 user 0.021037 sys 0.002864
    Run Time: real 0.059 user 0.018397 sys 0.003668
    ```

    After indexes and materialized view:

    ```
    Run Time: real 0.063 user 0.008671 sys 0.004898
    Run Time: real 0.053 user 0.010671 sys 0.003334
    Run Time: real 0.053 user 0.010337 sys 0.002884
    Run Time: real 0.052 user 0.008087 sys 0.002165
    Run Time: real 0.045 user 0.007265 sys 0.002123
    Run Time: real 0.038 user 0.008793 sys 0.002240
    Run Time: real 0.040 user 0.011022 sys 0.002420
    Run Time: real 0.049 user 0.010004 sys 0.002831
    Run Time: real 0.059 user 0.010472 sys 0.003661
    Run Time: real 0.046 user 0.009968 sys 0.002628
    ```
</details>

<br />

All of this leads me to believe that this isn't actually the right place to try to eat my own dogfood.
I can still practice what I preach, by caring about performance.
Yet I can think that an Application Performance Monitoring (APM) or Observability tool
would be a better fit for this use case than Bencher.
And that is okay!

[bencher perf]: /perf/bencher
[adapters]: /docs/explanation/adapters/
[continuous benchmarking load testing]: /docs/explanation/continuous-benchmarking/#continuous-benchmarking-vs-continuous-load-testing


## Bonus Bug

I originally had a bug in my [materialized view][materialized view] code.
This is what the SQL query looked like:

```sql
SELECT branch.id, branch.uuid, branch.project_id, branch.name, branch.slug, branch.start_point_id, branch.created, branch.modified, testbed.id, testbed.uuid, testbed.project_id, testbed.name, testbed.slug, testbed.created, testbed.modified, benchmark.id, benchmark.uuid, benchmark.project_id, benchmark.name, benchmark.slug, benchmark.created, benchmark.modified, measure.id, measure.uuid, measure.project_id, measure.name, measure.slug, measure.units, measure.created, measure.modified, report.uuid, report_benchmark.iteration, report.start_time, report.end_time, version.number, version.hash, threshold.id, threshold.uuid, threshold.project_id, threshold.measure_id, threshold.branch_id, threshold.testbed_id, threshold.model_id, threshold.created, threshold.modified, model.id, model.uuid, model.threshold_id, model.test, model.min_sample_size, model.max_sample_size, model.window, model.lower_boundary, model.upper_boundary, model.created, model.replaced, alert.id, alert.uuid, alert.boundary_id, alert.boundary_limit, alert.status, alert.modified, metric_boundary.metric_id, metric_boundary.metric_uuid, metric_boundary.report_benchmark_id, metric_boundary.measure_id, metric_boundary.value, metric_boundary.lower_value, metric_boundary.upper_value, metric_boundary.boundary_id, metric_boundary.boundary_uuid, metric_boundary.threshold_id, metric_boundary.model_id, metric_boundary.baseline, metric_boundary.lower_limit, metric_boundary.upper_limit FROM (((((metric_boundary INNER JOIN ((report_benchmark INNER JOIN ((report INNER JOIN (version INNER JOIN (branch_version INNER JOIN branch ON (branch_version.branch_id = branch.id)) ON (branch_version.version_id = version.id)) ON (report.version_id = version.id)) INNER JOIN testbed ON (report.testbed_id = testbed.id)) ON (report_benchmark.report_id = report.id)) INNER JOIN benchmark ON (report_benchmark.benchmark_id = benchmark.id)) ON (metric_boundary.report_benchmark_id = report_benchmark.id)) INNER JOIN measure ON (metric_boundary.measure_id = measure.id)) LEFT OUTER JOIN threshold ON (metric_boundary.threshold_id = threshold.id)) LEFT OUTER JOIN model ON (metric_boundary.model_id = model.id)) LEFT OUTER JOIN alert ON (alert.boundary_id = metric_boundary.metric_id)) WHERE ((((((branch.uuid = 'a7d8366a-4f9b-452e-987e-2ae56e4bf4a3') AND (testbed.uuid = '5b4a6f3e-a27d-4cc3-a2ce-851dc6421e6e')) AND (benchmark.uuid = '88375e7c-f1e0-4cbb-bde1-bdb7773022ae')) AND (measure.uuid = 'b2275bbc-2044-4f8e-aecd-3c739bd861b9')) AND (report.start_time >= 0)) AND (report.end_time <= 1712838648197)) ORDER BY version.number, report.start_time, report_benchmark.iteration;
```

Do you see the problem? Nope. Neither did I!

The issue is right here:

```sql
LEFT OUTER JOIN alert ON (alert.boundary_id = metric_boundary.metric_id)
```

It should actually be:


```sql
LEFT OUTER JOIN alert ON (alert.boundary_id = metric_boundary.boundary_id)
```

I was trying to be too clever,
and in my Diesel materialized view schema I had allowed this join:

```rust
diesel::joinable!(alert -> metric_boundary (boundary_id));
```

I assumed that this macro was somehow smart enough
to relate the `alert.boundary_id` to the `metric_boundary.boundary_id`.
But alas, it was not.
It seems to have just picked the first column of `metric_boundary` (`metric_id`) to relate to `alert`.

Once I discovered the bug, it was easy to fix.
I just had to use an explicit join in the Perf query:

```rust
.left_join(schema::alert::table.on(view::metric_boundary::boundary_id.eq(schema::alert::boundary_id.nullable())))
```

<br />

> üê∞ That's all folks!

[materialized view]: #materialized-view

